{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c4dc733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PyIOmica 1.3.3 (https://github.com/gmiaslab/pyiomica by G. Mias Lab)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/user/home/sahaj432/Desktop/code_organized/G_signal_feature_reduction_Project/New_neural_code/pyiomica_master/pyiomica/visibilityGraphAuxiliaryFunctions.py:91: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit(cache=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pyiomica_master import pyiomica as pio\n",
    "from pyiomica_master.pyiomica import visualizationFunctions\n",
    "from pyiomica_master.pyiomica import visibilityGraphCommunityDetection\n",
    "import matplotlib as mpl\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b297825b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_frame1_05 = np.genfromtxt('/home/sahaj432/Desktop/dataset/neural_4_class/x_frame1_2_seed.csv', delimiter=',')\n",
    "x_frame2_05 = np.genfromtxt('/home/sahaj432/Desktop/dataset/neural_4_class/x_frame2_2_seed.csv', delimiter=',')\n",
    "x_frame3_05 = np.genfromtxt('/home/sahaj432/Desktop/dataset/neural_4_class/x_frame3_2_seed.csv', delimiter=',')\n",
    "x_framen_05= np.genfromtxt('/home/sahaj432/Desktop/dataset/neural_4_class/x_frame_noise_2_seed.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79eaf877",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.concatenate((x_frame1_05,x_frame2_05,x_frame3_05,x_framen_05),axis=0)\n",
    "y=np.concatenate((np.zeros(len(x_frame1_05)),np.zeros(len(x_frame2_05))+1,np.zeros(len(x_frame3_05))+2,np.zeros(len(x_framen_05))+3),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ea7e902",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = shuffle(x,y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b78a4e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_adj(data):\n",
    "    temp1=[]\n",
    "    for p, i in enumerate(data):\n",
    "        #print(f'Converting ==> {p+1} \\r', end=\"\",flush=True)\n",
    "        vs_out = visibilityGraphCommunityDetection.createVisibilityGraph(i, range(len(i)), \"natural\", weight='tan')\n",
    "        temp1.append(vs_out)\n",
    "        \n",
    "    return np.asarray(temp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72622fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def degree(data): #The node strengths (or weighted degrees) \n",
    "    return np.sum(data != 0, axis=1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90597a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def weighted_clustering_coefficient(matrix):\n",
    "    n = len(matrix)\n",
    "    Cw = np.zeros(n)\n",
    "\n",
    "    for i in range(n):\n",
    "        neighbors = np.nonzero(matrix[i])[0]\n",
    "        if len(neighbors) < 2:\n",
    "            continue\n",
    "\n",
    "        # Calculate the sum in the numerator\n",
    "        triples = [(j, h) for idx, j in enumerate(neighbors) for h in neighbors[idx + 1:] if matrix[j,h] > 0]\n",
    "        numer = np.sum([(matrix[i, j] * matrix[i, h] * matrix[j, h]) ** (1/3) for j, h in triples])\n",
    "\n",
    "        # The max number of triangles node i can be part of\n",
    "        max_triangles = len(neighbors) * (len(neighbors) - 1) / 2\n",
    "\n",
    "        Cw[i] = numer / max_triangles if max_triangles != 0 else 0\n",
    "\n",
    "    return Cw\n",
    "\n",
    "# Test the function with your matrix\n",
    "# You'll need to define your matrix here or replace with a sample matrix\n",
    "# print(weighted_clustering_coefficient(your_matrix))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d75824f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_index_complexity(matrix):\n",
    "    N = len(matrix) # Number of nodes\n",
    "    E = np.sum(matrix > 0) / 2 # Number of edges (since matrix is symmetric for undirected graphs)\n",
    "    \n",
    "    if N == 0 or E == 0:\n",
    "        return 0\n",
    "    \n",
    "    GIC = (E / N) * np.log(N)\n",
    "    return GIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "685dadd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def dijkstra(matrix, source):\n",
    "    n = len(matrix)\n",
    "    visited = [False] * n\n",
    "    distances = [float('inf')] * n\n",
    "    distances[source] = 0\n",
    "\n",
    "    for _ in range(n):\n",
    "        # Select the unvisited node with the smallest distance\n",
    "        u = np.argmin([distances[i] if not visited[i] else float('inf') for i in range(n)])\n",
    "        visited[u] = True\n",
    "\n",
    "        # Update the distances for its neighboring nodes\n",
    "        for v in range(n):\n",
    "            if matrix[u][v] > 0 and not visited[v]:\n",
    "                distances[v] = min(distances[v], distances[u] + 1/matrix[u][v])\n",
    "\n",
    "    return distances\n",
    "\n",
    "def global_efficiency(matrix):\n",
    "    n = len(matrix)\n",
    "    avg_inverse_distance = 0.0\n",
    "    \n",
    "    for i in range(n):\n",
    "        distances = dijkstra(matrix, i)\n",
    "        avg_inverse_distance += sum(1/d for d in distances if d > 0)\n",
    "\n",
    "    return avg_inverse_distance / (n * (n - 1))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80c137ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def dijkstra(matrix, source):\n",
    "    n = len(matrix)\n",
    "    visited = [False] * n\n",
    "    distances = [float('inf')] * n\n",
    "    distances[source] = 0\n",
    "\n",
    "    for _ in range(n):\n",
    "        # Select the unvisited node with the smallest distance\n",
    "        u = np.argmin([distances[i] if not visited[i] else float('inf') for i in range(n)])\n",
    "        visited[u] = True\n",
    "\n",
    "        # Update the distances for its neighboring nodes\n",
    "        for v in range(n):\n",
    "            if matrix[u][v] > 0 and not visited[v]:\n",
    "                distances[v] = min(distances[v], distances[u] + 1/matrix[u][v])\n",
    "\n",
    "    return distances\n",
    "\n",
    "def global_efficiency(matrix):\n",
    "    n = len(matrix)\n",
    "    \n",
    "    # If the matrix represents a graph/subgraph with only one node, return 0 (or 1).\n",
    "    if n == 1:\n",
    "        return 0  # or return 1, based on your interpretation\n",
    "    \n",
    "    avg_inverse_distance = 0.0\n",
    "    \n",
    "    for i in range(n):\n",
    "        distances = dijkstra(matrix, i)\n",
    "        avg_inverse_distance += sum(1/d for d in distances if d > 0)\n",
    "\n",
    "    return avg_inverse_distance / (n * (n - 1))\n",
    "\n",
    "def local_efficiency(matrix):\n",
    "    n = len(matrix)\n",
    "    total_local_efficiency = 0.0\n",
    "    \n",
    "    for i in range(n):\n",
    "        # Get neighbors of node i\n",
    "        neighbors = [j for j, w in enumerate(matrix[i]) if w > 0]\n",
    "        \n",
    "        # Create a subgraph of node i's neighbors\n",
    "        subgraph = np.array([[matrix[a][b] for b in neighbors] for a in neighbors])\n",
    "        \n",
    "        # Add the global efficiency of the subgraph to the total\n",
    "        total_local_efficiency += global_efficiency(subgraph)\n",
    "\n",
    "    return total_local_efficiency / n\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e3eaf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assortative_coefficient_weighted_corrected(A):\n",
    "    # Calculate strengths of each node\n",
    "    strengths = np.sum(A, axis=1)\n",
    "    \n",
    "    # Calculate terms for the assortative coefficient formula\n",
    "    M = np.sum(A)\n",
    "    term1 = np.sum(A * np.outer(strengths, strengths))\n",
    "    term2 = np.sum(A * strengths)\n",
    "    term3 = np.sum(A * np.outer(strengths**2, strengths))\n",
    "    term4 = np.sum(A * np.outer(strengths, strengths**2))\n",
    "    \n",
    "    numerator = term1 - (term2**2 / M)\n",
    "    denominator = np.sqrt((term3 - (term2**2 / M)) * (term4 - (term2**2 / M)))\n",
    "    \n",
    "    # Calculate the assortative coefficient\n",
    "    r = numerator / denominator\n",
    "    \n",
    "    return r\n",
    "\n",
    "# Test with the sample adjacency matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2201b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-include the dijkstra function from the provided code\n",
    "\n",
    "def dijkstra(matrix, source):\n",
    "    n = len(matrix)\n",
    "    visited = [False] * n\n",
    "    distances = [float('inf')] * n\n",
    "    distances[source] = 0\n",
    "\n",
    "    for _ in range(n):\n",
    "        # Select the unvisited node with the smallest distance\n",
    "        u = np.argmin([distances[i] if not visited[i] else float('inf') for i in range(n)])\n",
    "        visited[u] = True\n",
    "\n",
    "        # Update the distances for its neighboring nodes\n",
    "        for v in range(n):\n",
    "            if matrix[u][v] > 0 and not visited[v]:\n",
    "                distances[v] = min(distances[v], distances[u] + 1/matrix[u][v])\n",
    "\n",
    "    return distances\n",
    "\n",
    "# Test the characteristic_path_length function with the sample adjacency matrix\n",
    "def characteristic_path_length_from_matrix(matrix):\n",
    "    # Calculate the sum of shortest path lengths between all pairs of nodes\n",
    "    total_path_length = 0.0\n",
    "    n = len(matrix)\n",
    "    for i in range(n):\n",
    "        distances = dijkstra(matrix, i)\n",
    "        total_path_length += sum(d for d in distances if d < float('inf') and d > 0)\n",
    "\n",
    "    # Compute the average shortest path length for the entire network\n",
    "    avg_path_length = total_path_length / (n * (n - 1))\n",
    "    \n",
    "    return avg_path_length\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "705b4e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import community\n",
    "\n",
    "def compute_modularity_louvain(weighted_adjacency_matrix):\n",
    "   \n",
    "\n",
    "    # Convert the weighted adjacency matrix to a NetworkX graph\n",
    "    G = nx.from_numpy_array(weighted_adjacency_matrix)\n",
    "\n",
    "    # Compute the best partition using the Louvain method\n",
    "    partition = community.best_partition(G, weight='weight')\n",
    "\n",
    "    # Calculate and return the modularity\n",
    "    return community.modularity(partition, G, weight='weight')\n",
    "\n",
    "# You can now call this function with your adjacency matrix\n",
    "# For demonstration purposes, I'll use the previously defined matrix_sample\n",
    "# compute_modularity_louvain(matrix_sample)  # Uncomment this to test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8fd44f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/ipykernel_191796/3762583850.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "  entropy = -np.nansum(P * np.log(P))\n",
      "/scratch/local/ipykernel_191796/3762583850.py:9: RuntimeWarning: invalid value encountered in multiply\n",
      "  entropy = -np.nansum(P * np.log(P))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.343344811455955"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weighted_graph_entropy(A):\n",
    "    # Calculate the sum of all weights in the graph\n",
    "    total_weight = np.sum(A)\n",
    "    \n",
    "    # Calculate the probabilities\n",
    "    P = A / total_weight\n",
    "    \n",
    "    # Compute the entropy\n",
    "    entropy = -np.nansum(P * np.log(P))\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6ba1edd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def dijkstra(matrix, source):\n",
    "    n = len(matrix)\n",
    "    visited = [False] * n\n",
    "    distances = [float('inf')] * n\n",
    "    distances[source] = 0\n",
    "\n",
    "    for _ in range(n):\n",
    "        # Select the unvisited node with the smallest distance\n",
    "        u = np.argmin([distances[i] if not visited[i] else float('inf') for i in range(n)])\n",
    "        visited[u] = True\n",
    "\n",
    "        # Update the distances for its neighboring nodes\n",
    "        for v in range(n):\n",
    "            if matrix[u][v] > 0 and not visited[v]:\n",
    "                distances[v] = min(distances[v], distances[u] + 1/matrix[u][v])\n",
    "\n",
    "    return distances\n",
    "\n",
    "def global_efficiency(matrix):\n",
    "    n = len(matrix)\n",
    "    \n",
    "    # If the matrix represents a graph/subgraph with only one node, return 0 (or 1).\n",
    "    if n == 1:\n",
    "        return 0  # or return 1, based on your interpretation\n",
    "    \n",
    "    avg_inverse_distance = 0.0\n",
    "    \n",
    "    for i in range(n):\n",
    "        distances = dijkstra(matrix, i)\n",
    "        avg_inverse_distance += sum(1/d for d in distances if d > 0)\n",
    "\n",
    "    return avg_inverse_distance / (n * (n - 1))\n",
    "\n",
    "def local_efficiency_per_node(matrix):\n",
    "    n = len(matrix)\n",
    "    local_efficiencies = np.zeros(n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        # Get neighbors of node i\n",
    "        neighbors = [j for j, w in enumerate(matrix[i]) if w > 0]\n",
    "        \n",
    "        # Create a subgraph of node i's neighbors\n",
    "        subgraph = np.array([[matrix[a][b] for b in neighbors] for a in neighbors])\n",
    "        \n",
    "        # If the matrix represents a graph/subgraph with less than 2 nodes, set efficiency to 0 (or 1).\n",
    "        if len(subgraph) < 2:\n",
    "            local_efficiencies[i] = 0  # or set to 1 based on interpretation\n",
    "            continue\n",
    "        \n",
    "        # Compute the global efficiency of the subgraph\n",
    "        local_efficiencies[i] = global_efficiency(subgraph)\n",
    "\n",
    "    return local_efficiencies\n",
    "\n",
    "# Sample weighted adjacency matrix for testing\n",
    "\n",
    "\n",
    "# Calculate local efficiency for each node using the sample weighted adjacency matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ebb0937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def betweenness_centrality_weighted_optimized(matrix):\n",
    "    # Convert the weighted adjacency matrix to a NetworkX graph\n",
    "    G = nx.from_numpy_array(matrix, parallel_edges=False)\n",
    "    \n",
    "    # Use NetworkX's betweenness centrality function\n",
    "    betweenness = nx.betweenness_centrality(G, weight='weight')\n",
    "    \n",
    "    return np.array(list(betweenness.values()))\n",
    "\n",
    "# Calculate betweenness centrality for each node using the sample weighted adjacency matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3797976",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def transitivity(adj_matrix):\n",
    "    # Binarize the adjacency matrix\n",
    "    binarized_matrix = (adj_matrix > 0).astype(int)\n",
    "\n",
    "    # Calculate the number of triangles\n",
    "    tri_matrix = np.linalg.matrix_power(binarized_matrix, 3)\n",
    "    triangles = np.trace(tri_matrix) / 2\n",
    "\n",
    "    # Calculate the number of connected triples\n",
    "    degree = binarized_matrix.sum(axis=1)\n",
    "    triples = (degree * (degree - 1)).sum() / 2\n",
    "\n",
    "    if triples == 0:\n",
    "        return 0\n",
    "\n",
    "    return (3 * triangles) / triples\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346e40f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def small_worldness_binary(adj_matrix):\n",
    "    # Binarize the adjacency matrix\n",
    "    binarized_matrix = (adj_matrix > 0).astype(int)\n",
    "    \n",
    "    # Convert the binarized matrix to a NetworkX graph\n",
    "    G = nx.from_numpy_array(binarized_matrix)\n",
    "\n",
    "    # Compute the clustering coefficient and average shortest path length\n",
    "    C = nx.average_clustering(G)\n",
    "    L = nx.average_shortest_path_length(G)\n",
    "\n",
    "    # Generate a random graph with the same number of nodes and edges\n",
    "    edges = G.number_of_edges()\n",
    "    nodes = G.number_of_nodes()\n",
    "    G_rand = nx.gnm_random_graph(nodes, edges)\n",
    "\n",
    "    # Compute the clustering coefficient and average shortest path length for the random graph\n",
    "    C_rand = nx.average_clustering(G_rand)\n",
    "    L_rand = nx.average_shortest_path_length(G_rand)\n",
    "\n",
    "    # Handle the case where C_rand or L_rand are zero\n",
    "    if C_rand == 0 or L_rand == 0:\n",
    "        return float('inf')  # Return infinity if we cannot compute the ratio\n",
    "\n",
    "    # Compute the small-world metric\n",
    "    sigma = (C / C_rand) / (L / L_rand)\n",
    "\n",
    "    return sigma\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ca97e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eigenvector_centrality(adj_matrix):\n",
    "    # Convert the adjacency matrix to a NetworkX graph\n",
    "    G = nx.from_numpy_array(adj_matrix)\n",
    "    \n",
    "    # Compute the eigenvector centrality\n",
    "    centrality = nx.eigenvector_centrality(G, weight='weight')\n",
    "    \n",
    "    return centrality.values()\n",
    "\n",
    "# Compute the eigenvector centrality for the adjacency matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b55ca07",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_adj=calculate_adj(X[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e93f952",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_worldness_binary(x_adj[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc701caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvector_centrality(x_adj[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0928bac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transitivity(x_adj[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9d30f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.160612197764719"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_index_complexity(x_adj[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d974b1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010143527829089926"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_efficiency(x_adj[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "76d9c382",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023357772466126553"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_efficiency(x_adj[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fcee2a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.026871416188148554"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assortative_coefficient_weighted_corrected(x_adj[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0098e494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190.24741684146207"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characteristic_path_length_from_matrix(x_adj[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19375b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6423063252736687"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_modularity_louvain(x_adj[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d4aee55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/ipykernel_191796/3762583850.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "  entropy = -np.nansum(P * np.log(P))\n",
      "/scratch/local/ipykernel_191796/3762583850.py:9: RuntimeWarning: invalid value encountered in multiply\n",
      "  entropy = -np.nansum(P * np.log(P))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.339920484285098"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test with the sample weighted adjacency matrix\n",
    "weighted_graph_entropy(x_adj[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54baab6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.0394694 , 0.02343751, 0.01124097,\n",
       "       0.01865743, 0.03643393, 0.02182349, 0.02221026, 0.02365797,\n",
       "       0.01708786, 0.02182415, 0.01678538, 0.01569603, 0.01656763,\n",
       "       0.016741  , 0.02420214, 0.03528079, 0.02742685, 0.02120216,\n",
       "       0.0133003 , 0.0157363 , 0.01950583, 0.01443528, 0.00750726,\n",
       "       0.0149049 , 0.0008545 , 0.01730727, 0.02098472, 0.01539971,\n",
       "       0.02054881, 0.05041159, 0.04962764, 0.03517576, 0.04578013,\n",
       "       0.0682962 , 0.06586373, 0.07387109, 0.03386639, 0.02048438,\n",
       "       0.0184028 , 0.00647563, 0.01554928, 0.04602792, 0.07446439,\n",
       "       0.0634067 , 0.02323432, 0.05193284, 0.04329819, 0.02863654,\n",
       "       0.02083148, 0.02218251, 0.01486778, 0.02110545, 0.02385797,\n",
       "       0.02239915])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_efficiency_per_node(x_adj[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6810c3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07205387, 0.        , 0.        , 0.39393939, 0.        ,\n",
       "       0.07205387, 0.        , 0.10505051, 0.        , 0.        ,\n",
       "       0.07003367, 0.14276094, 0.03636364, 0.        , 0.        ,\n",
       "       0.        , 0.35084175, 0.        , 0.        , 0.        ,\n",
       "       0.21144781, 0.09090909, 0.03636364, 0.        , 0.07609428,\n",
       "       0.        , 0.04040404, 0.        , 0.03636364, 0.0006734 ,\n",
       "       0.        , 0.1016835 , 0.30572391, 0.        , 0.        ,\n",
       "       0.47138047, 0.01010101, 0.11380471, 0.16498316, 0.        ,\n",
       "       0.03771044, 0.        , 0.0996633 , 0.        , 0.01616162,\n",
       "       0.        , 0.        , 0.        , 0.01212121, 0.06464646,\n",
       "       0.0040404 , 0.43569024, 0.        , 0.10639731, 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_betweenness_values_optimized = betweenness_centrality_weighted_optimized(x_adj[3])\n",
    "node_betweenness_values_optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd69135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "x_e1=[]\n",
    "for i in x_adj:\n",
    "    a=weighted_clustering_coefficient(i)\n",
    "    b=degree(i)\n",
    "    x_e1.append(np.concatenate((a, b.flatten()),axis=0))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b47aff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_e1=np.array(x_e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584b0d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_temp, y_train, y_temp = train_test_split(x_e1, Y, test_size=0.30, random_state=42)\n",
    "x_val,x_test,y_val,y_test=train_test_split(x_temp,y_temp,test_size=0.50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ff4de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee715d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51d8943",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (x_train.shape[1],1)\n",
    "num_classes = 4\n",
    "model3 = tf.keras.models.Sequential()\n",
    "model3.add(tf.keras.layers.Conv1D(filters= 32, kernel_size=3, activation='relu',padding='same',input_shape= input_shape))\n",
    "model3.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=None,padding='valid'))\n",
    "\n",
    "model3.add(tf.keras.layers.Conv1D(filters=32, kernel_size=3,padding='same',activation='relu'))\n",
    "model3.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=None,padding='valid'))\n",
    "\n",
    "model3.add(tf.keras.layers.Conv1D(filters=32, kernel_size=3,padding='same',activation='relu'))\n",
    "model3.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=None,padding='valid'))\n",
    "model3.add(tf.keras.layers.Conv1D(filters=32, kernel_size=3,padding='same',activation='relu'))\n",
    "model3.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=None,padding='valid'))\n",
    "model3.add(tf.keras.layers.Conv1D(filters=32, kernel_size=3,padding='same',activation='relu'))\n",
    "model3.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=None,padding='valid'))\n",
    "model3.add(tf.keras.layers.Conv1D(filters=32, kernel_size=3,padding='same',activation='relu'))\n",
    "model3.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=None,padding='valid'))\n",
    "model3.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model3.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model3.add(tf.keras.layers.Dropout(0.1))\n",
    "model3.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model3.add(tf.keras.layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f1d97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5691f34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss='SparseCategoricalCrossentropy', optimizer='Adam', metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bf0926",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_log=model3.fit(x_train, y_train, epochs=20,verbose=1,validation_data=(x_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994f96a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model3.predict(x_test)\n",
    "pred_arg = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb59028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cnf_matrix=confusion_matrix(y_test,pred_arg)\n",
    "print(\"cnf_matrix_2.0_70\")\n",
    "print(\"\")\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f134881",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score,precision_score,roc_auc_score,roc_curve,f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f419b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test,pred_arg)*100)\n",
    "print(f1_score(y_test,pred_arg,average='macro')*100)\n",
    "print(recall_score(y_test,pred_arg, average=\"weighted\")*100)\n",
    "print(precision_score(y_test,pred_arg, average=\"weighted\")*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6122db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90845a20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5cac89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
