{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89e29f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PyIOmica 1.3.3 (https://github.com/gmiaslab/pyiomica by G. Mias Lab)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pyiomica_master import pyiomica as pio\n",
    "from pyiomica_master.pyiomica import visualizationFunctions\n",
    "from pyiomica_master.pyiomica import visibilityGraphCommunityDetection\n",
    "import matplotlib as mpl\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b297825b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_frame1_05 = np.genfromtxt('/home/nvekariy/signal_code/datasets/neural_4_class/x_frame1_1.25_seed.csv', delimiter=',')\n",
    "x_frame2_05 = np.genfromtxt('/home/nvekariy/signal_code/datasets/neural_4_class/x_frame2_1.25_seed.csv', delimiter=',')\n",
    "x_frame3_05 = np.genfromtxt('/home/nvekariy/signal_code/datasets/neural_4_class/x_frame3_1.25_seed.csv', delimiter=',')\n",
    "x_framen_05= np.genfromtxt('/home/nvekariy/signal_code/datasets/neural_4_class/x_frame_noise_1.25_seed.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61feafd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "112c6fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.concatenate((x_frame1_05,x_frame2_05,x_frame3_05,x_framen_05),axis=0)\n",
    "y=np.concatenate((np.zeros(len(x_frame1_05)),np.zeros(len(x_frame2_05))+1,np.zeros(len(x_frame3_05))+2,np.zeros(len(x_framen_05))+3),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfcfbda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = shuffle(x,y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7898816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_adj(data):\n",
    "    temp1=[]\n",
    "    for p, i in enumerate(data):\n",
    "        #print(f'Converting ==> {p+1} \\r', end=\"\",flush=True)\n",
    "        vs_out = visibilityGraphCommunityDetection.createVisibilityGraph(i, range(len(i)), \"dual_natural\", weight='tan')\n",
    "        temp1.append(vs_out)\n",
    "        \n",
    "    return temp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a609f105",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 48\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    print(\"Number of CPU cores:\", num_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cef4d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "658\n"
     ]
    }
   ],
   "source": [
    "df=np.array_split(X, num_cores)\n",
    "print(len(df[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cf6a2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(processes=num_cores) as pool:\n",
    "    results = pool.map(calculate_adj, df)\n",
    "\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f80b2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_adj=[]\n",
    "for submatrix in results:\n",
    "    x_adj.extend(submatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55dc354c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_adj=np.array(x_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65307fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31578, 56, 56)\n"
     ]
    }
   ],
   "source": [
    "print(x_adj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39aadf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_adj=x_adj.reshape(x_adj.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89f0a5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31578, 3136)\n"
     ]
    }
   ],
   "source": [
    "print(x_adj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f7b49ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 26.60760998725891 seconds ---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import IncrementalPCA\n",
    "n_components=112\n",
    "batch_size=2000\n",
    "ipca = IncrementalPCA(n_components=n_components, batch_size=batch_size)\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(0, x_adj.shape[0], batch_size):\n",
    "    ipca.partial_fit(x_adj[i:i+batch_size])\n",
    "\n",
    "X_ipca = ipca.transform(x_adj)\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c585c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcb8fbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_temp, y_train, y_temp = train_test_split(X_ipca, Y, test_size=0.30, random_state=42)\n",
    "x_val,x_test,y_val,y_test=train_test_split(x_temp,y_temp,test_size=0.50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ab593cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22104, 112)\n",
      "(4737, 112)\n",
      "(4737, 112)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1022f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-13 10:17:55.331386: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-13 10:17:55.450728: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-13 10:17:55.455181: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/slurm/18.08.9/lib64/slurm:/cm/shared/apps/slurm/18.08.9/lib64\n",
      "2023-08-13 10:17:55.455198: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-08-13 10:18:04.121808: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/slurm/18.08.9/lib64/slurm:/cm/shared/apps/slurm/18.08.9/lib64\n",
      "2023-08-13 10:18:04.121895: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/slurm/18.08.9/lib64/slurm:/cm/shared/apps/slurm/18.08.9/lib64\n",
      "2023-08-13 10:18:04.121907: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "041aca53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-13 10:18:17.856871: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/slurm/18.08.9/lib64/slurm:/cm/shared/apps/slurm/18.08.9/lib64\n",
      "2023-08-13 10:18:17.856900: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-08-13 10:18:17.856919: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (c0153): /proc/driver/nvidia/version does not exist\n",
      "2023-08-13 10:18:17.857536: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "input_shape = (x_train.shape[1],1)\n",
    "num_classes = 4\n",
    "model3 = tf.keras.models.Sequential()\n",
    "model3.add(tf.keras.layers.Conv1D(filters= 32, kernel_size=3, activation='relu',padding='same',input_shape= input_shape))\n",
    "model3.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=None,padding='valid'))\n",
    "\n",
    "model3.add(tf.keras.layers.Conv1D(filters=32, kernel_size=3,padding='same',activation='relu'))\n",
    "model3.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=None,padding='valid'))\n",
    "\n",
    "# model3.add(tf.keras.layers.Conv1D(filters=32, kernel_size=3,padding='same',activation='relu'))\n",
    "# model3.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=None,padding='valid'))\n",
    "# model3.add(tf.keras.layers.Conv1D(filters=32, kernel_size=3,padding='same',activation='relu'))\n",
    "# model3.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=None,padding='valid'))\n",
    "# model3.add(tf.keras.layers.Conv1D(filters=32, kernel_size=3,padding='same',activation='relu'))\n",
    "# model3.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=None,padding='valid'))\n",
    "# model3.add(tf.keras.layers.Conv1D(filters=32, kernel_size=3,padding='same',activation='relu'))\n",
    "# model3.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=None,padding='valid'))\n",
    "model3.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model3.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "model3.add(tf.keras.layers.Dropout(0.1))\n",
    "model3.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "model3.add(tf.keras.layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d7a5c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 112, 32)           128       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 56, 32)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 56, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 28, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 896)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               89700     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 103,436\n",
      "Trainable params: 103,436\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6573d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss='SparseCategoricalCrossentropy', optimizer='Adam', metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2276cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint('F7.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43bf0926",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "690/691 [============================>.] - ETA: 0s - loss: 0.2267 - acc: 0.9160WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "691/691 [==============================] - 4s 4ms/step - loss: 0.2267 - acc: 0.9160 - val_loss: 0.0924 - val_acc: 0.9717\n",
      "Epoch 2/30\n",
      "683/691 [============================>.] - ETA: 0s - loss: 0.0799 - acc: 0.9752WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.0797 - acc: 0.9753 - val_loss: 0.0791 - val_acc: 0.9755\n",
      "Epoch 3/30\n",
      "676/691 [============================>.] - ETA: 0s - loss: 0.0695 - acc: 0.9772WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.0694 - acc: 0.9772 - val_loss: 0.0723 - val_acc: 0.9793\n",
      "Epoch 4/30\n",
      "682/691 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9808WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.0606 - acc: 0.9809 - val_loss: 0.0777 - val_acc: 0.9766\n",
      "Epoch 5/30\n",
      "684/691 [============================>.] - ETA: 0s - loss: 0.0551 - acc: 0.9819WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.0552 - acc: 0.9819 - val_loss: 0.0647 - val_acc: 0.9810\n",
      "Epoch 6/30\n",
      "682/691 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9825WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.0523 - acc: 0.9826 - val_loss: 0.0913 - val_acc: 0.9728\n",
      "Epoch 7/30\n",
      "681/691 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9851WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.0472 - acc: 0.9850 - val_loss: 0.0691 - val_acc: 0.9808\n",
      "Epoch 8/30\n",
      "690/691 [============================>.] - ETA: 0s - loss: 0.0452 - acc: 0.9850WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.0452 - acc: 0.9850 - val_loss: 0.0781 - val_acc: 0.9791\n",
      "Epoch 9/30\n",
      "677/691 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9861WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.0433 - acc: 0.9859 - val_loss: 0.0690 - val_acc: 0.9816\n",
      "Epoch 10/30\n",
      "686/691 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9873WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.0376 - acc: 0.9873 - val_loss: 0.0708 - val_acc: 0.9797\n",
      "Epoch 11/30\n",
      "683/691 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9876WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.0345 - acc: 0.9876 - val_loss: 0.0693 - val_acc: 0.9802\n",
      "Epoch 12/30\n",
      "679/691 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9895WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.0313 - acc: 0.9895 - val_loss: 0.0724 - val_acc: 0.9802\n",
      "Epoch 13/30\n",
      "678/691 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9909WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.0263 - acc: 0.9908 - val_loss: 0.0808 - val_acc: 0.9780\n",
      "Epoch 14/30\n",
      "690/691 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9920WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.0231 - acc: 0.9920 - val_loss: 0.0848 - val_acc: 0.9795\n",
      "Epoch 15/30\n",
      "688/691 [============================>.] - ETA: 0s - loss: 0.0217 - acc: 0.9922WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.0217 - acc: 0.9923 - val_loss: 0.0920 - val_acc: 0.9785\n",
      "Epoch 16/30\n",
      "691/691 [==============================] - ETA: 0s - loss: 0.0171 - acc: 0.9943WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.0171 - acc: 0.9943 - val_loss: 0.0968 - val_acc: 0.9780\n",
      "Epoch 17/30\n",
      "683/691 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9954WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.0139 - acc: 0.9954 - val_loss: 0.1134 - val_acc: 0.9776\n",
      "Epoch 18/30\n",
      "684/691 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9947WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.0153 - acc: 0.9947 - val_loss: 0.0958 - val_acc: 0.9816\n",
      "Epoch 19/30\n",
      "684/691 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9956WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.0135 - acc: 0.9955 - val_loss: 0.1075 - val_acc: 0.9774\n",
      "Epoch 20/30\n",
      "685/691 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9955WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.0129 - acc: 0.9955 - val_loss: 0.1097 - val_acc: 0.9793\n",
      "Epoch 21/30\n",
      "682/691 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9967WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.0098 - acc: 0.9967 - val_loss: 0.1218 - val_acc: 0.9808\n",
      "Epoch 22/30\n",
      "688/691 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9965WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.0092 - acc: 0.9964 - val_loss: 0.1218 - val_acc: 0.9802\n",
      "Epoch 23/30\n",
      "679/691 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9955WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.0120 - acc: 0.9953 - val_loss: 0.1269 - val_acc: 0.9776\n",
      "Epoch 24/30\n",
      "691/691 [==============================] - ETA: 0s - loss: 0.0081 - acc: 0.9973WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.0081 - acc: 0.9973 - val_loss: 0.1172 - val_acc: 0.9808\n",
      "Epoch 25/30\n",
      "682/691 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9985WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.0047 - acc: 0.9985 - val_loss: 0.1551 - val_acc: 0.9799\n",
      "Epoch 26/30\n",
      "688/691 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9975WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.0078 - acc: 0.9975 - val_loss: 0.1352 - val_acc: 0.9816\n",
      "Epoch 27/30\n",
      "686/691 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9976WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.0070 - acc: 0.9976 - val_loss: 0.1290 - val_acc: 0.9797\n",
      "Epoch 28/30\n",
      "683/691 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9971WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.0096 - acc: 0.9971 - val_loss: 0.1229 - val_acc: 0.9808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "682/691 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9981WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.0055 - acc: 0.9981 - val_loss: 0.1496 - val_acc: 0.9795\n",
      "Epoch 30/30\n",
      "682/691 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9985WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.0045 - acc: 0.9985 - val_loss: 0.1495 - val_acc: 0.9797\n"
     ]
    }
   ],
   "source": [
    "history_log = model3.fit(x_train, y_train, epochs=30, verbose=1, validation_data=(x_test, y_test), callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de84a26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save_weights('/home/nvekariy/signal_code/New_neural_code_SNR_1.25_h/F7.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30fd3f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.load_weights('/home/nvekariy/signal_code/New_neural_code_SNR_1.25_h/F7.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "994f96a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model3.predict(x_test)\n",
    "pred_arg = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abb59028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnf_matrix_2.0_70\n",
      "\n",
      "[[ 940    1    0    6]\n",
      " [   0  942   32    8]\n",
      " [   0   24  974    3]\n",
      " [  15    6    1 1785]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cnf_matrix=confusion_matrix(y_test,pred_arg)\n",
    "print(\"cnf_matrix_2.0_70\")\n",
    "print(\"\")\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f134881",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score,precision_score,roc_auc_score,roc_curve,f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f419b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.97340088663711\n",
      "97.7857324250964\n",
      "97.97340088663711\n",
      "97.97315529319307\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,pred_arg)*100)\n",
    "print(f1_score(y_test,pred_arg,average='macro')*100)\n",
    "print(recall_score(y_test,pred_arg, average=\"weighted\")*100)\n",
    "print(precision_score(y_test,pred_arg, average=\"weighted\")*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cadd42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba39972",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
