{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d05515c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PyIOmica 1.3.3 (https://github.com/gmiaslab/pyiomica by G. Mias Lab)\n"
     ]
    }
   ],
   "source": [
    "#%matplotlib notebook\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pyiomica_master import pyiomica as pio\n",
    "from pyiomica_master.pyiomica import visualizationFunctions\n",
    "from pyiomica_master.pyiomica import visibilityGraphCommunityDetection\n",
    "import matplotlib as mpl\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "686a7503",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"/home/nvekariy/signal_code/datasets/Bonn_seizure_dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "614feb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path=glob.glob(data_path+\"***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6d6ce99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/nvekariy/signal_code/datasets/Bonn_seizure_dataset/Set_A',\n",
       " '/home/nvekariy/signal_code/datasets/Bonn_seizure_dataset/Set_B',\n",
       " '/home/nvekariy/signal_code/datasets/Bonn_seizure_dataset/Set_C',\n",
       " '/home/nvekariy/signal_code/datasets/Bonn_seizure_dataset/Set_D',\n",
       " '/home/nvekariy/signal_code/datasets/Bonn_seizure_dataset/Set_E']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63b0db82",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_C1 = 0\n",
    "LABEL_C2 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0af44a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data = []\n",
    "    nbFiles = 0\n",
    "    df=glob.glob(df_path[1]+\"/***\")\n",
    "    for fname in tqdm(df):\n",
    "        img = np.loadtxt(fname)\n",
    "        data.append([img, np.array(LABEL_C1)])\n",
    "        nbFiles+=1\n",
    "        \n",
    "    df1=glob.glob(df_path[-1]+\"/***\")\n",
    "    for fname in tqdm(df1):\n",
    "        img = np.loadtxt(fname)\n",
    "        data.append([np.array(img), np.array(LABEL_C2)])\n",
    "        nbFiles+=1\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eb10476",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 42.47it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 46.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 Files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = load_data()\n",
    "print(len(data), \"Files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b171d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "data = shuffle(data,random_state=40)\n",
    "\n",
    "\n",
    "X = np.array([d[0] for d in data])\n",
    "Y = np.array([d[1] for d in data])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "debcb8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 4097)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c2a9453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalize(matrix):\n",
    "    \"\"\"\n",
    "    Perform min-max normalization on a 2D array (matrix).\n",
    "    \"\"\"\n",
    "    min_vals = np.min(matrix, axis=0)\n",
    "    max_vals = np.max(matrix, axis=0)\n",
    "    normalized = (matrix - min_vals) / (max_vals - min_vals)\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db6481d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_n=np.array([min_max_normalize(i) for i in X])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8076da9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp=[]\n",
    "Y_temp=[]\n",
    "for i in range(len(X)):\n",
    "        raw=X_n[i]\n",
    "        X_temp.append(raw[:1024])\n",
    "        X_temp.append(raw[1024:2048])\n",
    "        X_temp.append(raw[2048:3072])\n",
    "        X_temp.append(raw[3072:4096])\n",
    "        \n",
    "        Y_temp.extend(np.repeat(Y[i],4))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b12c9280",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp=np.array(X_temp)\n",
    "Y_temp=np.array(Y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e193f953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 1024)\n",
      "(800,)\n"
     ]
    }
   ],
   "source": [
    "print(X_temp.shape)\n",
    "print(Y_temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2649374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X_s,Y_s = shuffle(X_temp,Y_temp,random_state=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d146de01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique elements: 2\n",
      "Unique elements: [0 1]\n",
      "Element counts: [400 400]\n"
     ]
    }
   ],
   "source": [
    "unique_elements, element_counts = np.unique(Y_s, return_counts=True)\n",
    "\n",
    "print(\"Number of unique elements:\", len(unique_elements))\n",
    "print(\"Unique elements:\", unique_elements)\n",
    "print(\"Element counts:\", element_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "435d1111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_visibility(data):\n",
    "    temp1=[]\n",
    "    for p, i in enumerate(data):\n",
    "        #print(f'Converting ==> {p+1} \\r', end=\"\",flush=True)\n",
    "        vs_out = visibilityGraphCommunityDetection.createVisibilityGraph(i, range(len(i)), \"dual_natural\", weight='tan')\n",
    "        vs_out=np.array(vs_out)\n",
    "        temp1.append(vs_out)\n",
    "        \n",
    "    return temp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f814f207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 48\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    print(\"Number of CPU cores:\", num_cores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8658c689",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=np.array_split(X_s, num_cores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d503a8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "print(len(df[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a1b59a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(processes=num_cores) as pool:\n",
    "    results = pool.map(calculate_visibility, df)\n",
    "\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a34da891",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_adj=[]\n",
    "for submatrix in results:\n",
    "    x_adj.extend(submatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "663f8024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n"
     ]
    }
   ],
   "source": [
    "print(len(x_adj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a005b24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_adj=np.array(x_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "721c5235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_g(data):\n",
    "    temp2=[]\n",
    "    for vs_out in data:\n",
    "        a = np.sum(vs_out, axis=0).reshape(-1, 1)\n",
    "        b = np.sum(vs_out != 0, axis=1).reshape(-1, 1)\n",
    "        temp2.append(np.concatenate((a, b), axis=1))\n",
    "        \n",
    "    return temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c582fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 48\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    print(\"Number of CPU cores:\", num_cores)\n",
    "\n",
    "\n",
    "df1=np.array_split(x_adj[:], num_cores)\n",
    "\n",
    "\n",
    "print(len(df[0]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "489e53ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 11.220099210739136 seconds ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "with Pool(processes=num_cores) as pool1:\n",
    "    results1 = pool1.map(calculate_g, df1)\n",
    "\n",
    "pool1.close()\n",
    "pool1.join()\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4bd5c260",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_g=[]\n",
    "for submatrix in results1:\n",
    "    x_g.extend(submatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7087c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_g=np.array(x_g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a1404fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 1024, 2)\n"
     ]
    }
   ],
   "source": [
    "print(x_g.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ea53b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_g_flat=np.array([np.array(i.T.flatten()).ravel() for i in x_g])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b0168e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "584b0d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_g_flat, Y_s, test_size=0.30, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87ff4de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(560, 2048)\n",
      "(240, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ee715d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-12 09:05:28.813491: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-12 09:05:28.944243: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-12 09:05:28.948757: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/slurm/18.08.9/lib64/slurm:/cm/shared/apps/slurm/18.08.9/lib64\n",
      "2023-08-12 09:05:28.948773: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-08-12 09:05:38.035494: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/slurm/18.08.9/lib64/slurm:/cm/shared/apps/slurm/18.08.9/lib64\n",
      "2023-08-12 09:05:38.035615: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/slurm/18.08.9/lib64/slurm:/cm/shared/apps/slurm/18.08.9/lib64\n",
      "2023-08-12 09:05:38.035625: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a51d8943",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-12 09:05:50.441665: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/slurm/18.08.9/lib64/slurm:/cm/shared/apps/slurm/18.08.9/lib64\n",
      "2023-08-12 09:05:50.441695: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-08-12 09:05:50.441715: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (c0155): /proc/driver/nvidia/version does not exist\n",
      "2023-08-12 09:05:50.442477: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "input_shape = (x_train.shape[1],1)\n",
    "num_classes = 4\n",
    "model3 = tf.keras.models.Sequential()\n",
    "model3.add(tf.keras.layers.Conv1D(filters= 32, kernel_size=3, activation='relu',padding='same',input_shape= input_shape))\n",
    "model3.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=None,padding='valid'))\n",
    "\n",
    "model3.add(tf.keras.layers.Conv1D(filters=32, kernel_size=3,padding='same',activation='relu'))\n",
    "model3.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=None,padding='valid'))\n",
    "\n",
    "model3.add(tf.keras.layers.Conv1D(filters=32, kernel_size=3,padding='same',activation='relu'))\n",
    "model3.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=None,padding='valid'))\n",
    "model3.add(tf.keras.layers.Conv1D(filters=32, kernel_size=3,padding='same',activation='relu'))\n",
    "model3.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=None,padding='valid'))\n",
    "model3.add(tf.keras.layers.Conv1D(filters=32, kernel_size=3,padding='same',activation='relu'))\n",
    "model3.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=None,padding='valid'))\n",
    "model3.add(tf.keras.layers.Conv1D(filters=32, kernel_size=3,padding='same',activation='relu'))\n",
    "model3.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=None,padding='valid'))\n",
    "model3.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model3.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "model3.add(tf.keras.layers.Dropout(0.1))\n",
    "model3.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "model3.add(tf.keras.layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "09f1d97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 2048, 32)          128       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 1024, 32)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 1024, 32)          3104      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 512, 32)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 512, 32)           3104      \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 256, 32)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 256, 32)           3104      \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 128, 32)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 128, 32)           3104      \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 64, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 64, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 32, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               102500    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 128,652\n",
      "Trainable params: 128,652\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5691f34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss='SparseCategoricalCrossentropy', optimizer='Adam', metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "120604a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint('F8.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "43bf0926",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.8965 - acc: 0.5146   WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 2s 30ms/step - loss: 0.8718 - acc: 0.4964 - val_loss: 0.6712 - val_acc: 0.5875\n",
      "Epoch 2/30\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.6668 - acc: 0.5762WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.6671 - acc: 0.5714 - val_loss: 0.6168 - val_acc: 0.7625\n",
      "Epoch 3/30\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.5495 - acc: 0.6934WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.5440 - acc: 0.7000 - val_loss: 0.4087 - val_acc: 0.8542\n",
      "Epoch 4/30\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.3817 - acc: 0.8398WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.3667 - acc: 0.8482 - val_loss: 0.2911 - val_acc: 0.8917\n",
      "Epoch 5/30\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.2852 - acc: 0.8770WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.3017 - acc: 0.8607 - val_loss: 0.4181 - val_acc: 0.8042\n",
      "Epoch 6/30\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.3627 - acc: 0.8301WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.3530 - acc: 0.8375 - val_loss: 0.3939 - val_acc: 0.8042\n",
      "Epoch 7/30\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.2239 - acc: 0.9102WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.2328 - acc: 0.9071 - val_loss: 0.2834 - val_acc: 0.8750\n",
      "Epoch 8/30\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.2588 - acc: 0.9004WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.2547 - acc: 0.9036 - val_loss: 0.3546 - val_acc: 0.7917\n",
      "Epoch 9/30\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.2076 - acc: 0.9219WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.1968 - acc: 0.9286 - val_loss: 0.2661 - val_acc: 0.9000\n",
      "Epoch 10/30\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1081 - acc: 0.9648WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.1141 - acc: 0.9643 - val_loss: 0.1937 - val_acc: 0.8958\n",
      "Epoch 11/30\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1816 - acc: 0.9395WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.2053 - acc: 0.9286 - val_loss: 0.1583 - val_acc: 0.9458\n",
      "Epoch 12/30\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1359 - acc: 0.9414WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.1358 - acc: 0.9429 - val_loss: 0.1815 - val_acc: 0.9125\n",
      "Epoch 13/30\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0876 - acc: 0.9648WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0839 - acc: 0.9661 - val_loss: 0.1600 - val_acc: 0.9542\n",
      "Epoch 14/30\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0507 - acc: 0.9844WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0511 - acc: 0.9821 - val_loss: 0.1156 - val_acc: 0.9667\n",
      "Epoch 15/30\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0338 - acc: 0.9902WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0347 - acc: 0.9911 - val_loss: 0.1494 - val_acc: 0.9583\n",
      "Epoch 16/30\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0340 - acc: 0.9902WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0371 - acc: 0.9857 - val_loss: 0.1154 - val_acc: 0.9542\n",
      "Epoch 17/30\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0411 - acc: 0.9863WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0397 - acc: 0.9857 - val_loss: 0.1098 - val_acc: 0.9625\n",
      "Epoch 18/30\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0182 - acc: 0.9961WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0180 - acc: 0.9964 - val_loss: 0.1183 - val_acc: 0.9667\n",
      "Epoch 19/30\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0080 - acc: 1.0000WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.1003 - val_acc: 0.9708\n",
      "Epoch 20/30\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0042 - acc: 1.0000WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.1536 - val_acc: 0.9667\n",
      "Epoch 21/30\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0045 - acc: 1.0000WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.1166 - val_acc: 0.9708\n",
      "Epoch 22/30\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0023 - acc: 1.0000WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1224 - val_acc: 0.9708\n",
      "Epoch 23/30\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0019 - acc: 1.0000WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.1126 - val_acc: 0.9750\n",
      "Epoch 24/30\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0014 - acc: 1.0000WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1371 - val_acc: 0.9708\n",
      "Epoch 25/30\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8.8495e-04 - acc: 1.0000WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 9.0144e-04 - acc: 1.0000 - val_loss: 0.1244 - val_acc: 0.9750\n",
      "Epoch 26/30\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8.2299e-04 - acc: 1.0000WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 7.9006e-04 - acc: 1.0000 - val_loss: 0.1303 - val_acc: 0.9750\n",
      "Epoch 27/30\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 7.2566e-04 - acc: 1.0000WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 7.4378e-04 - acc: 1.0000 - val_loss: 0.1532 - val_acc: 0.9708\n",
      "Epoch 28/30\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 6.1573e-04 - acc: 1.0000WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 6.5184e-04 - acc: 1.0000 - val_loss: 0.1909 - val_acc: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0011 - acc: 1.0000  WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1960 - val_acc: 0.9625\n",
      "Epoch 30/30\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 6.7884e-04 - acc: 1.0000WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 6.6132e-04 - acc: 1.0000 - val_loss: 0.1636 - val_acc: 0.9708\n"
     ]
    }
   ],
   "source": [
    "history_log = model3.fit(x_train, y_train, epochs=30, verbose=1, validation_data=(x_test, y_test), callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "56a8f02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save_weights('/home/nvekariy/signal_code/New_bone_eeg_code_B_E_h/F8.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3a299a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.load_weights('/home/nvekariy/signal_code/New_bone_eeg_code_B_E_h/F8.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "994f96a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model3.predict(x_test)\n",
    "pred_arg = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "abb59028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnf_matrix_2.0_70\n",
      "\n",
      "[[110   1]\n",
      " [  6 123]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cnf_matrix=confusion_matrix(y_test,pred_arg)\n",
    "print(\"cnf_matrix_2.0_70\")\n",
    "print(\"\")\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9f134881",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score,precision_score,roc_auc_score,roc_curve,f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f419b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.08333333333333\n",
      "97.0747505702495\n",
      "97.08333333333333\n",
      "97.17429087875416\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,pred_arg)*100)\n",
    "print(f1_score(y_test,pred_arg,average='macro')*100)\n",
    "print(recall_score(y_test,pred_arg, average=\"weighted\")*100)\n",
    "print(precision_score(y_test,pred_arg, average=\"weighted\")*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6122db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dedc27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3eacb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
