{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c4dc733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PyIOmica 1.3.3 (https://github.com/gmiaslab/pyiomica by G. Mias Lab)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/user/home/sahaj432/Desktop/code_organized/G_signal_feature_reduction_Project/New_neural_code_SNR_0.5_v/pyiomica_master/pyiomica/visibilityGraphAuxiliaryFunctions.py:91: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit(cache=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pyiomica_master import pyiomica as pio\n",
    "from pyiomica_master.pyiomica import visualizationFunctions\n",
    "from pyiomica_master.pyiomica import visibilityGraphCommunityDetection\n",
    "import matplotlib as mpl\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b297825b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_frame1_05 = np.genfromtxt('/home/sahaj432/Desktop/dataset/neural_4_class/x_frame1_0.5_seed.csv', delimiter=',')\n",
    "x_frame2_05 = np.genfromtxt('/home/sahaj432/Desktop/dataset/neural_4_class/x_frame2_0.5_seed.csv', delimiter=',')\n",
    "x_frame3_05 = np.genfromtxt('/home/sahaj432/Desktop/dataset/neural_4_class/x_frame3_0.5_seed.csv', delimiter=',')\n",
    "x_framen_05= np.genfromtxt('/home/sahaj432/Desktop/dataset/neural_4_class/x_frame_noise_0.5_seed.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f7372f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79eaf877",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.concatenate((x_frame1_05,x_frame2_05,x_frame3_05,x_framen_05[:6000]),axis=0)\n",
    "y=np.concatenate((np.zeros(len(x_frame1_05)),np.zeros(len(x_frame2_05))+1,np.zeros(len(x_frame3_05))+2,np.zeros(len(x_framen_05[:6000]))+3),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ea7e902",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = shuffle(x,y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b78a4e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_adj(data):\n",
    "    temp1=[]\n",
    "    for p, i in enumerate(data):\n",
    "        #print(f'Converting ==> {p+1} \\r', end=\"\",flush=True)\n",
    "        vs_out = visibilityGraphCommunityDetection.createVisibilityGraph(i, range(len(i)), \"natural\", weight='tan')\n",
    "        vs_out=np.asarray(vs_out)\n",
    "        temp1.append(vs_out)\n",
    "        \n",
    "    return temp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a666b1e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 48\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    print(\"Number of CPU cores:\", num_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c9f289e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534\n"
     ]
    }
   ],
   "source": [
    "df=np.array_split(X, num_cores)\n",
    "print(len(df[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25c7ec9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(processes=num_cores) as pool:\n",
    "    results = pool.map(calculate_adj, df)\n",
    "\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d507239",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_adj=[]\n",
    "for submatrix in results:\n",
    "    x_adj.extend(submatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb4be57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25615\n"
     ]
    }
   ],
   "source": [
    "print(len(x_adj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37e26890",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_adj=np.array(x_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fe37ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def degree(data): #The node strengths (or weighted degrees) \n",
    "    return np.average(np.sum(data, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe9d74c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "def runall(data):\n",
    "    temp1=[]\n",
    "    for i in data:\n",
    "        G = nx.from_numpy_array(i, parallel_edges=False)\n",
    "        \n",
    "        t=[nx.transitivity(G)]\n",
    "        ge=[nx.global_efficiency(G)]\n",
    "        le=[nx.local_efficiency(G)]\n",
    "        \n",
    "        cc=list(nx.clustering(G).values())\n",
    "        temp1.append(t+ge+le+cc) #+cpl+ge+le+ac+cc\n",
    "    return temp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c582fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 48\n",
      "534\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    print(\"Number of CPU cores:\", num_cores)\n",
    "\n",
    "\n",
    "df1=np.array_split(x_adj[:], num_cores)\n",
    "\n",
    "\n",
    "print(len(df[0]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "489e53ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 25.345372438430786 seconds ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "with Pool(processes=num_cores) as pool1:\n",
    "    results1 = pool1.map(runall, df1)\n",
    "\n",
    "pool1.close()\n",
    "pool1.join()\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bd5c260",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_g=[]\n",
    "for submatrix in results1:\n",
    "    x_g.extend(submatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7087c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_g=np.array(x_g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a1404fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25615, 59)\n"
     ]
    }
   ],
   "source": [
    "print(x_g.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "584b0d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_temp, y_train, y_temp = train_test_split(x_g, Y, test_size=0.30, random_state=42)\n",
    "x_val,x_test,y_val,y_test=train_test_split(x_temp,y_temp,test_size=0.50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87ff4de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17930, 59)\n",
      "(3842, 59)\n",
      "(3843, 59)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ee715d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-13 09:03:58.940990: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/slurm/18.08.9/lib64/slurm:/cm/shared/apps/slurm/18.08.9/lib64\n",
      "2023-08-13 09:03:58.941033: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a51d8943",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-13 09:04:25.697358: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/slurm/18.08.9/lib64/slurm:/cm/shared/apps/slurm/18.08.9/lib64\n",
      "2023-08-13 09:04:25.709559: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-08-13 09:04:25.709662: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (c0161): /proc/driver/nvidia/version does not exist\n",
      "2023-08-13 09:04:25.814953: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "input_shape = (x_train.shape[1],1)\n",
    "num_classes = 4\n",
    "model3 = tf.keras.models.Sequential()\n",
    "model3.add(tf.keras.layers.Conv1D(filters= 32, kernel_size=3, activation='relu',padding='same',input_shape= input_shape))\n",
    "model3.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=None,padding='valid'))\n",
    "\n",
    "model3.add(tf.keras.layers.Conv1D(filters=32, kernel_size=3,padding='same',activation='relu'))\n",
    "model3.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=None,padding='valid'))\n",
    "\n",
    "# model3.add(tf.keras.layers.Conv1D(filters=32, kernel_size=3,padding='same',activation='relu'))\n",
    "# model3.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=None,padding='valid'))\n",
    "# model3.add(tf.keras.layers.Conv1D(filters=32, kernel_size=3,padding='same',activation='relu'))\n",
    "# model3.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=None,padding='valid'))\n",
    "# model3.add(tf.keras.layers.Conv1D(filters=32, kernel_size=3,padding='same',activation='relu'))\n",
    "# model3.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=None,padding='valid'))\n",
    "# model3.add(tf.keras.layers.Conv1D(filters=32, kernel_size=3,padding='same',activation='relu'))\n",
    "# model3.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=None,padding='valid'))\n",
    "model3.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model3.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "model3.add(tf.keras.layers.Dropout(0.1))\n",
    "model3.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "model3.add(tf.keras.layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09f1d97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 59, 32)            128       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 29, 32)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 29, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 14, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 448)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               44900     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58,636\n",
      "Trainable params: 58,636\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5691f34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss='SparseCategoricalCrossentropy', optimizer='Adam', metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "722b40ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint('F5.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43bf0926",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "559/561 [============================>.] - ETA: 0s - loss: 0.2756 - acc: 0.8993WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "561/561 [==============================] - 4s 3ms/step - loss: 0.2753 - acc: 0.8994 - val_loss: 0.1145 - val_acc: 0.9560\n",
      "Epoch 2/30\n",
      "558/561 [============================>.] - ETA: 0s - loss: 0.0962 - acc: 0.9657WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 0.0962 - acc: 0.9658 - val_loss: 0.0721 - val_acc: 0.9758\n",
      "Epoch 3/30\n",
      "551/561 [============================>.] - ETA: 0s - loss: 0.0803 - acc: 0.9729WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 0.0798 - acc: 0.9731 - val_loss: 0.0686 - val_acc: 0.9750\n",
      "Epoch 4/30\n",
      "553/561 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9769WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 0.0712 - acc: 0.9768 - val_loss: 0.0752 - val_acc: 0.9750\n",
      "Epoch 5/30\n",
      "553/561 [============================>.] - ETA: 0s - loss: 0.0648 - acc: 0.9793WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 0.0649 - acc: 0.9793 - val_loss: 0.0680 - val_acc: 0.9766\n",
      "Epoch 6/30\n",
      "542/561 [===========================>..] - ETA: 0s - loss: 0.0624 - acc: 0.9796WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 0.0617 - acc: 0.9799 - val_loss: 0.0765 - val_acc: 0.9716\n",
      "Epoch 7/30\n",
      "545/561 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9808WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 0.0586 - acc: 0.9811 - val_loss: 0.0544 - val_acc: 0.9810\n",
      "Epoch 8/30\n",
      "545/561 [============================>.] - ETA: 0s - loss: 0.0564 - acc: 0.9810WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 0.0566 - acc: 0.9810 - val_loss: 0.0714 - val_acc: 0.9753\n",
      "Epoch 9/30\n",
      "553/561 [============================>.] - ETA: 0s - loss: 0.0531 - acc: 0.9821WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 0.0528 - acc: 0.9823 - val_loss: 0.0768 - val_acc: 0.9750\n",
      "Epoch 10/30\n",
      "542/561 [===========================>..] - ETA: 0s - loss: 0.0512 - acc: 0.9829WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 0.0515 - acc: 0.9830 - val_loss: 0.0537 - val_acc: 0.9836\n",
      "Epoch 11/30\n",
      "544/561 [============================>.] - ETA: 0s - loss: 0.0466 - acc: 0.9837WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 0.0463 - acc: 0.9838 - val_loss: 0.0511 - val_acc: 0.9846\n",
      "Epoch 12/30\n",
      "560/561 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9851WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 0.0448 - acc: 0.9851 - val_loss: 0.0603 - val_acc: 0.9813\n",
      "Epoch 13/30\n",
      "558/561 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9865WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 0.0403 - acc: 0.9864 - val_loss: 0.0554 - val_acc: 0.9807\n",
      "Epoch 14/30\n",
      "550/561 [============================>.] - ETA: 0s - loss: 0.0396 - acc: 0.9857WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 0.0397 - acc: 0.9856 - val_loss: 0.0861 - val_acc: 0.9714\n",
      "Epoch 15/30\n",
      "545/561 [============================>.] - ETA: 0s - loss: 0.0350 - acc: 0.9878WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 0.0350 - acc: 0.9878 - val_loss: 0.0524 - val_acc: 0.9820\n",
      "Epoch 16/30\n",
      "557/561 [============================>.] - ETA: 0s - loss: 0.0362 - acc: 0.9870WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 0.0361 - acc: 0.9871 - val_loss: 0.0583 - val_acc: 0.9841\n",
      "Epoch 17/30\n",
      "561/561 [==============================] - ETA: 0s - loss: 0.0374 - acc: 0.9864WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 0.0374 - acc: 0.9864 - val_loss: 0.0529 - val_acc: 0.9852\n",
      "Epoch 18/30\n",
      "550/561 [============================>.] - ETA: 0s - loss: 0.0315 - acc: 0.9889WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 0.0318 - acc: 0.9888 - val_loss: 0.0532 - val_acc: 0.9857\n",
      "Epoch 19/30\n",
      "553/561 [============================>.] - ETA: 0s - loss: 0.0315 - acc: 0.9884WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 0.0311 - acc: 0.9886 - val_loss: 0.0641 - val_acc: 0.9802\n",
      "Epoch 20/30\n",
      "545/561 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9899WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 0.0283 - acc: 0.9900 - val_loss: 0.0597 - val_acc: 0.9844\n",
      "Epoch 21/30\n",
      "541/561 [===========================>..] - ETA: 0s - loss: 0.0281 - acc: 0.9899WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 0.0283 - acc: 0.9898 - val_loss: 0.0612 - val_acc: 0.9833\n",
      "Epoch 22/30\n",
      "558/561 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9918WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 0.0232 - acc: 0.9917 - val_loss: 0.0614 - val_acc: 0.9852\n",
      "Epoch 23/30\n",
      "558/561 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9917WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 0.0230 - acc: 0.9917 - val_loss: 0.0615 - val_acc: 0.9859\n",
      "Epoch 24/30\n",
      "552/561 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9920WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 0.0231 - acc: 0.9920 - val_loss: 0.0742 - val_acc: 0.9826\n",
      "Epoch 25/30\n",
      "557/561 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9916WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 0.0251 - acc: 0.9916 - val_loss: 0.0862 - val_acc: 0.9774\n",
      "Epoch 26/30\n",
      "560/561 [============================>.] - ETA: 0s - loss: 0.0217 - acc: 0.9923WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 0.0217 - acc: 0.9923 - val_loss: 0.0678 - val_acc: 0.9836\n",
      "Epoch 27/30\n",
      "558/561 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9936WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 0.0183 - acc: 0.9936 - val_loss: 0.0706 - val_acc: 0.9831\n",
      "Epoch 28/30\n",
      "552/561 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9936WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 0.0183 - acc: 0.9936 - val_loss: 0.0649 - val_acc: 0.9859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "547/561 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9938WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 0.0178 - acc: 0.9938 - val_loss: 0.0685 - val_acc: 0.9862\n",
      "Epoch 30/30\n",
      "544/561 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9928WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 0.0189 - acc: 0.9929 - val_loss: 0.0670 - val_acc: 0.9859\n"
     ]
    }
   ],
   "source": [
    "history_log = model3.fit(x_train, y_train, epochs=30, verbose=1, validation_data=(x_test, y_test), callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44709207",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save_weights('/home/sahaj432/Desktop/code_organized/G_signal_feature_reduction_Project/New_neural_code_SNR_0.5_v/F5.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d09ba0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.load_weights('/home/sahaj432/Desktop/code_organized/G_signal_feature_reduction_Project/New_neural_code_SNR_0.5_v/F5.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "994f96a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model3.predict(x_test)\n",
    "pred_arg = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abb59028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnf_matrix_2.0_70\n",
      "\n",
      "[[949   2   0   0]\n",
      " [  1 953  32   0]\n",
      " [  0  13 986   0]\n",
      " [  2   3   1 901]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cnf_matrix=confusion_matrix(y_test,pred_arg)\n",
    "print(\"cnf_matrix_2.0_70\")\n",
    "print(\"\")\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f134881",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score,precision_score,roc_auc_score,roc_curve,f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f419b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.59484777517564\n",
      "98.62997107003883\n",
      "98.59484777517564\n",
      "98.60454804127696\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,pred_arg)*100)\n",
    "print(f1_score(y_test,pred_arg,average='macro')*100)\n",
    "print(recall_score(y_test,pred_arg, average=\"weighted\")*100)\n",
    "print(precision_score(y_test,pred_arg, average=\"weighted\")*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90845a20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd00c7be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
