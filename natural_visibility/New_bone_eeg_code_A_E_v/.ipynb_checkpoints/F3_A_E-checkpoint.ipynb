{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d05515c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PyIOmica 1.3.3 (https://github.com/gmiaslab/pyiomica by G. Mias Lab)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/user/home/sahaj432/Desktop/code_organized/G_signal_feature_reduction_Project/New_bone_eeg_code_A_E_v/pyiomica_master/pyiomica/visibilityGraphAuxiliaryFunctions.py:91: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit(cache=True)\n"
     ]
    }
   ],
   "source": [
    "#%matplotlib notebook\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pyiomica_master import pyiomica as pio\n",
    "from pyiomica_master.pyiomica import visualizationFunctions\n",
    "from pyiomica_master.pyiomica import visibilityGraphCommunityDetection\n",
    "import matplotlib as mpl\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "686a7503",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"/home/sahaj432/Desktop/dataset/Bonn_seizure_dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "614feb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path=glob.glob(data_path+\"***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6d6ce99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/sahaj432/Desktop/dataset/Bonn_seizure_dataset/Set_A',\n",
       " '/home/sahaj432/Desktop/dataset/Bonn_seizure_dataset/Set_B',\n",
       " '/home/sahaj432/Desktop/dataset/Bonn_seizure_dataset/Set_C',\n",
       " '/home/sahaj432/Desktop/dataset/Bonn_seizure_dataset/Set_D',\n",
       " '/home/sahaj432/Desktop/dataset/Bonn_seizure_dataset/Set_E']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63b0db82",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_C1 = 0\n",
    "LABEL_C2 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0af44a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data = []\n",
    "    nbFiles = 0\n",
    "    df=glob.glob(df_path[0]+\"/***\")\n",
    "    for fname in tqdm(df):\n",
    "        img = np.loadtxt(fname)\n",
    "        data.append([img, np.array(LABEL_C1)])\n",
    "        nbFiles+=1\n",
    "        \n",
    "    df1=glob.glob(df_path[-1]+\"/***\")\n",
    "    for fname in tqdm(df1):\n",
    "        img = np.loadtxt(fname)\n",
    "        data.append([np.array(img), np.array(LABEL_C2)])\n",
    "        nbFiles+=1\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eb10476",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 68.98it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 64.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 Files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = load_data()\n",
    "print(len(data), \"Files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b171d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "data = shuffle(data,random_state=40)\n",
    "\n",
    "\n",
    "X = np.array([d[0] for d in data])\n",
    "Y = np.array([d[1] for d in data])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "debcb8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 4097)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c2a9453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalize(matrix):\n",
    "    \"\"\"\n",
    "    Perform min-max normalization on a 2D array (matrix).\n",
    "    \"\"\"\n",
    "    min_vals = np.min(matrix, axis=0)\n",
    "    max_vals = np.max(matrix, axis=0)\n",
    "    normalized = (matrix - min_vals) / (max_vals - min_vals)\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db6481d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_n=np.array([min_max_normalize(i) for i in X])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8076da9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp=[]\n",
    "Y_temp=[]\n",
    "for i in range(len(X)):\n",
    "        raw=X_n[i]\n",
    "        X_temp.append(raw[:1024])\n",
    "        X_temp.append(raw[1024:2048])\n",
    "        X_temp.append(raw[2048:3072])\n",
    "        X_temp.append(raw[3072:4096])\n",
    "        \n",
    "        Y_temp.extend(np.repeat(Y[i],4))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b12c9280",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp=np.array(X_temp)\n",
    "Y_temp=np.array(Y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e193f953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 1024)\n",
      "(800,)\n"
     ]
    }
   ],
   "source": [
    "print(X_temp.shape)\n",
    "print(Y_temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2649374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X_s,Y_s = shuffle(X_temp,Y_temp,random_state=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d146de01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique elements: 2\n",
      "Unique elements: [0 1]\n",
      "Element counts: [400 400]\n"
     ]
    }
   ],
   "source": [
    "unique_elements, element_counts = np.unique(Y_s, return_counts=True)\n",
    "\n",
    "print(\"Number of unique elements:\", len(unique_elements))\n",
    "print(\"Unique elements:\", unique_elements)\n",
    "print(\"Element counts:\", element_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "435d1111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_visibility(data):\n",
    "    temp1=[]\n",
    "    for p, i in enumerate(data):\n",
    "        #print(f'Converting ==> {p+1} \\r', end=\"\",flush=True)\n",
    "        vs_out = visibilityGraphCommunityDetection.createVisibilityGraph(i, range(len(i)), \"natural\", weight='tan')\n",
    "        vs_out=np.array(vs_out)\n",
    "        temp1.append(vs_out)\n",
    "        \n",
    "    return temp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f814f207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 48\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    print(\"Number of CPU cores:\", num_cores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8658c689",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=np.array_split(X_s, num_cores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d503a8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "print(len(df[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a1b59a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(processes=num_cores) as pool:\n",
    "    results = pool.map(calculate_visibility, df)\n",
    "\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a34da891",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_adj=[]\n",
    "for submatrix in results:\n",
    "    x_adj.extend(submatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "663f8024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n"
     ]
    }
   ],
   "source": [
    "print(len(x_adj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37e26890",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_adj=np.array(x_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a577d55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def degree(data): #The node strengths (or weighted degrees) \n",
    "    return np.sum(data, axis=0).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe9d74c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runall(data):\n",
    "    temp1=[]\n",
    "    for i in data:\n",
    "        G = nx.from_numpy_array(i, parallel_edges=False)\n",
    "        \n",
    "        m=[nx.community.modularity(G,nx.community.label_propagation_communities(G))]\n",
    "        cc=list(nx.clustering(G).values())\n",
    "        temp1.append(m+cc) #+cpl+ge+le+ac+cc\n",
    "    return temp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c582fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 48\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    print(\"Number of CPU cores:\", num_cores)\n",
    "\n",
    "\n",
    "df1=np.array_split(x_adj[:], num_cores)\n",
    "\n",
    "\n",
    "print(len(df[0]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "489e53ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 13.21930193901062 seconds ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "with Pool(processes=num_cores) as pool1:\n",
    "    results1 = pool1.map(runall, df1)\n",
    "\n",
    "pool1.close()\n",
    "pool1.join()\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4bd5c260",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_g=[]\n",
    "for submatrix in results1:\n",
    "    x_g.extend(submatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7087c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_g=np.array(x_g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a1404fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 1025)\n"
     ]
    }
   ],
   "source": [
    "print(x_g.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "584b0d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_g, Y_s, test_size=0.30, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87ff4de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(560, 1025)\n",
      "(240, 1025)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ee715d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-12 07:44:37.138670: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/slurm/18.08.9/lib64/slurm:/cm/shared/apps/slurm/18.08.9/lib64\n",
      "2023-08-12 07:44:37.138715: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a51d8943",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-12 07:44:59.284762: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/slurm/18.08.9/lib64/slurm:/cm/shared/apps/slurm/18.08.9/lib64\n",
      "2023-08-12 07:44:59.284796: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-08-12 07:44:59.284814: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (c0162): /proc/driver/nvidia/version does not exist\n",
      "2023-08-12 07:44:59.285071: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "input_shape = (x_train.shape[1],1)\n",
    "num_classes = 4\n",
    "model3 = tf.keras.models.Sequential()\n",
    "model3.add(tf.keras.layers.Conv1D(filters= 32, kernel_size=3, activation='relu',padding='same',input_shape= input_shape))\n",
    "model3.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=None,padding='valid'))\n",
    "\n",
    "model3.add(tf.keras.layers.Conv1D(filters=32, kernel_size=3,padding='same',activation='relu'))\n",
    "model3.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=None,padding='valid'))\n",
    "\n",
    "model3.add(tf.keras.layers.Conv1D(filters=32, kernel_size=3,padding='same',activation='relu'))\n",
    "model3.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=None,padding='valid'))\n",
    "model3.add(tf.keras.layers.Conv1D(filters=32, kernel_size=3,padding='same',activation='relu'))\n",
    "model3.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=None,padding='valid'))\n",
    "model3.add(tf.keras.layers.Conv1D(filters=32, kernel_size=3,padding='same',activation='relu'))\n",
    "model3.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=None,padding='valid'))\n",
    "model3.add(tf.keras.layers.Conv1D(filters=32, kernel_size=3,padding='same',activation='relu'))\n",
    "model3.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=None,padding='valid'))\n",
    "model3.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model3.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "model3.add(tf.keras.layers.Dropout(0.1))\n",
    "model3.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "model3.add(tf.keras.layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "09f1d97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 1025, 32)          128       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 512, 32)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 512, 32)           3104      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 256, 32)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 256, 32)           3104      \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 128, 32)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 128, 32)           3104      \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 64, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 64, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 32, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 32, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 16, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               51300     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77,452\n",
      "Trainable params: 77,452\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5691f34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss='SparseCategoricalCrossentropy', optimizer='Adam', metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4720703d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint('F3.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "43bf0926",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 1.1614 - acc: 0.4557WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 1.0343 - acc: 0.4607 - val_loss: 0.7629 - val_acc: 0.4625\n",
      "Epoch 2/30\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.7389 - acc: 0.5089WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.7334 - acc: 0.5179 - val_loss: 0.7208 - val_acc: 0.4625\n",
      "Epoch 3/30\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.7224 - acc: 0.4979WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.7196 - acc: 0.4946 - val_loss: 0.6958 - val_acc: 0.4625\n",
      "Epoch 4/30\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.6972 - acc: 0.4979WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.6973 - acc: 0.5018 - val_loss: 0.6963 - val_acc: 0.4625\n",
      "Epoch 5/30\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.6927 - acc: 0.5271WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.6921 - acc: 0.5357 - val_loss: 0.6910 - val_acc: 0.4625\n",
      "Epoch 6/30\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.6999 - acc: 0.4875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.6999 - acc: 0.4821 - val_loss: 0.6894 - val_acc: 0.8958\n",
      "Epoch 7/30\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.6663 - acc: 0.5562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.6667 - acc: 0.5589 - val_loss: 0.6376 - val_acc: 0.8958\n",
      "Epoch 8/30\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.5740 - acc: 0.7479WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5556 - acc: 0.7554 - val_loss: 0.3194 - val_acc: 0.9625\n",
      "Epoch 9/30\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.2268 - acc: 0.9396WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.2215 - acc: 0.9411 - val_loss: 0.1708 - val_acc: 0.9583\n",
      "Epoch 10/30\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1272 - acc: 0.9479WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1489 - acc: 0.9393 - val_loss: 0.2746 - val_acc: 0.8875\n",
      "Epoch 11/30\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.2020 - acc: 0.9208WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1914 - acc: 0.9232 - val_loss: 0.1213 - val_acc: 0.9750\n",
      "Epoch 12/30\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0810 - acc: 0.9729WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0744 - acc: 0.9768 - val_loss: 0.1216 - val_acc: 0.9750\n",
      "Epoch 13/30\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1030 - acc: 0.9604WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0904 - acc: 0.9661 - val_loss: 0.2733 - val_acc: 0.9042\n",
      "Epoch 14/30\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1274 - acc: 0.9438WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1292 - acc: 0.9464 - val_loss: 0.1658 - val_acc: 0.9458\n",
      "Epoch 15/30\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1288 - acc: 0.9521WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1174 - acc: 0.9554 - val_loss: 0.1368 - val_acc: 0.9625\n",
      "Epoch 16/30\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0780 - acc: 0.9771WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0731 - acc: 0.9786 - val_loss: 0.2334 - val_acc: 0.9250\n",
      "Epoch 17/30\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0668 - acc: 0.9808WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0752 - acc: 0.9750 - val_loss: 0.2310 - val_acc: 0.9333\n",
      "Epoch 18/30\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1317 - acc: 0.9563WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1263 - acc: 0.9571 - val_loss: 0.1176 - val_acc: 0.9708\n",
      "Epoch 19/30\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0481 - acc: 0.9854WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0629 - acc: 0.9804 - val_loss: 0.1263 - val_acc: 0.9708\n",
      "Epoch 20/30\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0513 - acc: 0.9896WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0592 - acc: 0.9857 - val_loss: 0.1201 - val_acc: 0.9750\n",
      "Epoch 21/30\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0698 - acc: 0.9792WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0877 - acc: 0.9750 - val_loss: 0.1216 - val_acc: 0.9750\n",
      "Epoch 22/30\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0807 - acc: 0.9754WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0756 - acc: 0.9768 - val_loss: 0.1188 - val_acc: 0.9750\n",
      "Epoch 23/30\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0484 - acc: 0.9854WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0482 - acc: 0.9857 - val_loss: 0.1243 - val_acc: 0.9750\n",
      "Epoch 24/30\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0387 - acc: 0.9896WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0434 - acc: 0.9893 - val_loss: 0.1240 - val_acc: 0.9708\n",
      "Epoch 25/30\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0485 - acc: 0.9854WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0429 - acc: 0.9875 - val_loss: 0.1788 - val_acc: 0.9583\n",
      "Epoch 26/30\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0341 - acc: 0.9917WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0312 - acc: 0.9911 - val_loss: 0.1735 - val_acc: 0.9667\n",
      "Epoch 27/30\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0437 - acc: 0.9792WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0413 - acc: 0.9821 - val_loss: 0.1320 - val_acc: 0.9750\n",
      "Epoch 28/30\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1015 - acc: 0.9667WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1020 - acc: 0.9679 - val_loss: 0.1122 - val_acc: 0.9708\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0848 - acc: 0.9663WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0793 - acc: 0.9661 - val_loss: 0.1217 - val_acc: 0.9708\n",
      "Epoch 30/30\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0602 - acc: 0.9771WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0529 - acc: 0.9804 - val_loss: 0.1887 - val_acc: 0.9583\n"
     ]
    }
   ],
   "source": [
    "history_log = model3.fit(x_train, y_train, epochs=30, verbose=1, validation_data=(x_test, y_test), callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad714c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save_weights('/home/sahaj432/Desktop/code_organized/G_signal_feature_reduction_Project/New_bone_eeg_code_A_E_v/F3.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ffb575ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.load_weights('/home/sahaj432/Desktop/code_organized/G_signal_feature_reduction_Project/New_bone_eeg_code_A_E_v/F3.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "994f96a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model3.predict(x_test)\n",
    "pred_arg = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "abb59028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnf_matrix_2.0_70\n",
      "\n",
      "[[110   1]\n",
      " [  9 120]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cnf_matrix=confusion_matrix(y_test,pred_arg)\n",
    "print(\"cnf_matrix_2.0_70\")\n",
    "print(\"\")\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9f134881",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score,precision_score,roc_auc_score,roc_curve,f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f419b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.83333333333334\n",
      "95.82608695652173\n",
      "95.83333333333334\n",
      "96.05788596430308\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,pred_arg)*100)\n",
    "print(f1_score(y_test,pred_arg,average='macro')*100)\n",
    "print(recall_score(y_test,pred_arg, average=\"weighted\")*100)\n",
    "print(precision_score(y_test,pred_arg, average=\"weighted\")*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6122db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dedc27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3eacb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
